{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112017,"databundleVersionId":13778912,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e8a30a12","cell_type":"code","source":"import os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\nprint('TF version:', tf.__version__)\n\n# Kaggle dataset paths\nTRAIN_DIR = Path('/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train')\nTRAIN_CSV = Path('/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/train.csv')\nSAMPLE_SUB = Path('/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/sample_submission.csv')\nTEST_DIR = Path('/kaggle/input/rice-pistachio-and-grapevine-leaf-classification/test')\n\nprint('Paths exist:')\nprint('TRAIN_DIR', TRAIN_DIR.exists())\nprint('TRAIN_CSV', TRAIN_CSV.exists())\nprint('SAMPLE_SUB', SAMPLE_SUB.exists())\nprint('TEST_DIR', TEST_DIR.exists())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:16:23.251596Z","iopub.execute_input":"2025-09-26T12:16:23.252622Z","iopub.status.idle":"2025-09-26T12:16:23.262938Z","shell.execute_reply.started":"2025-09-26T12:16:23.252593Z","shell.execute_reply":"2025-09-26T12:16:23.262220Z"}},"outputs":[{"name":"stdout","text":"TF version: 2.18.0\nPaths exist:\nTRAIN_DIR True\nTRAIN_CSV True\nSAMPLE_SUB True\nTEST_DIR True\n","output_type":"stream"}],"execution_count":2},{"id":"e6726409-bb81-467e-a9b2-36a3fa9de44b","cell_type":"markdown","source":"## Load labels and build train dataframe","metadata":{}},{"id":"415f6293","cell_type":"code","source":"# Read train.csv and create file paths\ntrain_df = pd.read_csv(str(TRAIN_CSV))\ntrain_df.columns = [c.strip() for c in train_df.columns]\ntrain_df.head()\n\n# Expecting columns like ['ID','TARGET'] or similar. Normalize names.\nif 'ID' not in train_df.columns and 'id' in train_df.columns:\n    train_df = train_df.rename(columns={'id':'ID'})\nif 'TARGET' not in train_df.columns and 'target' in train_df.columns:\n    train_df = train_df.rename(columns={'target':'TARGET'})\n\nprint('Columns:', train_df.columns.tolist())\n\n# Helper: find image path for an ID\nfrom functools import lru_cache\n@lru_cache(maxsize=None)\ndef find_image_path(image_id):\n    # first, check if file exists directly inside TRAIN_DIR\n    cand = TRAIN_DIR / image_id\n    if cand.exists():\n        return str(cand)\n    # else search recursively (this is slightly slower but robust)\n    for p in TRAIN_DIR.rglob(image_id):\n        return str(p)\n    # fallback: maybe image_id has extension missing; try common extensions\n    name = Path(image_id).stem\n    for ext in ['.jpg', '.jpeg', '.png']:\n        for p in TRAIN_DIR.rglob(name + ext):\n            return str(p)\n    return None\n\ntrain_df['filepath'] = train_df['ID'].astype(str).apply(find_image_path)\nmissing = train_df['filepath'].isnull().sum()\nprint('Missing file paths:', missing)\nif missing>0:\n    display(train_df[train_df['filepath'].isnull()].head())\n\n# Drop missing rows (if any)\ntrain_df = train_df.dropna(subset=['filepath']).reset_index(drop=True)\ntrain_df.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:16:27.556879Z","iopub.execute_input":"2025-09-26T12:16:27.557177Z","iopub.status.idle":"2025-09-26T12:16:51.377767Z","shell.execute_reply.started":"2025-09-26T12:16:27.557154Z","shell.execute_reply":"2025-09-26T12:16:51.377172Z"}},"outputs":[{"name":"stdout","text":"Columns: ['ID', 'TARGET']\nMissing file paths: 0\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(6400, 3)"},"metadata":{}}],"execution_count":3},{"id":"079fa54f","cell_type":"markdown","source":"## Label encoding and class distribution","metadata":{}},{"id":"81bb5b1a","cell_type":"code","source":"le = LabelEncoder()\ntrain_df['label_enc'] = le.fit_transform(train_df['TARGET'])\n\nprint('Number of classes:', len(le.classes_))\nclass_counts = train_df['TARGET'].value_counts()\nclass_counts.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:16:57.456109Z","iopub.execute_input":"2025-09-26T12:16:57.456507Z","iopub.status.idle":"2025-09-26T12:16:57.474023Z","shell.execute_reply.started":"2025-09-26T12:16:57.456473Z","shell.execute_reply":"2025-09-26T12:16:57.473080Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 20\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"TARGET\nBASMATI       400\nSIIRT         400\nKIRMIZI       400\nBINADHAN25    400\nBINADHAN16    400\nBRRI67        400\nBINADHAN7     400\nBD30          400\nJASMINE       400\nBD95          400\nARBORIO       400\nIPSALA        400\nBD72          400\nKARACADAG     400\nBR22          400\nAK             80\nNAZLI          80\nDIMNIT         80\nBUZGULU        80\nALA_IDRIS      80\nName: count, dtype: int64"},"metadata":{}}],"execution_count":4},{"id":"bb235de1","cell_type":"markdown","source":"## Stratified K-Fold","metadata":{}},{"id":"13c93392","cell_type":"code","source":"N_FOLDS = 5\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\ntrain_df['fold'] = -1\nfor fold, (_, val_idx) in enumerate(skf.split(train_df, train_df['label_enc'])):\n    train_df.loc[val_idx, 'fold'] = fold\n\ntrain_df.groupby('fold')['ID'].count()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:17:00.504950Z","iopub.execute_input":"2025-09-26T12:17:00.505313Z","iopub.status.idle":"2025-09-26T12:17:00.525949Z","shell.execute_reply.started":"2025-09-26T12:17:00.505289Z","shell.execute_reply":"2025-09-26T12:17:00.525240Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"fold\n0    1280\n1    1280\n2    1280\n3    1280\n4    1280\nName: ID, dtype: int64"},"metadata":{}}],"execution_count":5},{"id":"cf284d83","cell_type":"markdown","source":"## TF Dataset pipeline","metadata":{}},{"id":"9e83e824","cell_type":"code","source":"IMG_SIZE = (224,224)\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n\ndef read_and_preprocess(img_path, label=None, img_size=IMG_SIZE, is_training=False):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, img_size)\n    img = tf.cast(img, tf.float32)\n    if is_training:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_brightness(img, 0.1)\n    img = tf.keras.applications.efficientnet.preprocess_input(img)\n    if label is None:\n        return img\n    else:\n        return img, label\n\n\ndef make_dataset(filepaths, labels=None, batch_size=BATCH_SIZE, is_training=False):\n    files = tf.constant(filepaths)\n    if labels is None:\n        ds = tf.data.Dataset.from_tensor_slices(files)\n        ds = ds.map(lambda x: read_and_preprocess(x, None, IMG_SIZE, False), num_parallel_calls=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices((files, labels))\n        ds = ds.map(lambda x,y: read_and_preprocess(x, y, IMG_SIZE, is_training), num_parallel_calls=AUTOTUNE)\n        if is_training:\n            ds = ds.shuffle(2048)\n    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n    return ds\n\nprint('Dataset utilities ready')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:17:02.763678Z","iopub.execute_input":"2025-09-26T12:17:02.763955Z","iopub.status.idle":"2025-09-26T12:17:02.771958Z","shell.execute_reply.started":"2025-09-26T12:17:02.763934Z","shell.execute_reply":"2025-09-26T12:17:02.771106Z"}},"outputs":[{"name":"stdout","text":"Dataset utilities ready\n","output_type":"stream"}],"execution_count":6},{"id":"99a5a973","cell_type":"markdown","source":"## Model builder (EfficientNetB0)","metadata":{}},{"id":"0b84ddee","cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers, callbacks\n\ndef build_model(n_classes, input_shape=(224,224,3), train_base=False):\n    base = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n    base.trainable = train_base\n    inputs = tf.keras.Input(shape=input_shape)\n    x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n    x = base(x, training=False)\n    x = layers.Dropout(0.4)(x)\n    outputs = layers.Dense(n_classes, activation='softmax')(x)\n    model = models.Model(inputs, outputs)\n    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Quick instantiation\nmodel = build_model(len(le.classes_), input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), train_base=False)\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:17:07.085775Z","iopub.execute_input":"2025-09-26T12:17:07.086505Z","iopub.status.idle":"2025-09-26T12:17:12.511716Z","shell.execute_reply.started":"2025-09-26T12:17:07.086480Z","shell.execute_reply":"2025-09-26T12:17:12.510894Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1758889029.175365      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1758889029.176177      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │     \u001b[38;5;34m4,049,571\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │        \u001b[38;5;34m25,620\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,620</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,075,191\u001b[0m (15.55 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,075,191</span> (15.55 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,620\u001b[0m (100.08 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,620</span> (100.08 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n</pre>\n"},"metadata":{}}],"execution_count":7},{"id":"7e9fe436","cell_type":"markdown","source":"## Training loop (fold-wise)","metadata":{}},{"id":"d4639e6b","cell_type":"code","source":"# Training settings\nRUN_TRAIN = True\nEPOCHS = 15\nBATCH_SIZE = 32\nMODEL_DIR = Path('/kaggle/working')\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\n\nfrom tqdm import tqdm\n\nfold_hist = {}\nall_val_scores = []\nmodels_for_inference = []\n\nif RUN_TRAIN:\n    for fold in range(N_FOLDS):\n        print('\\n=== Fold', fold, '===')\n        train_f = train_df[train_df['fold']!=fold]\n        val_f = train_df[train_df['fold']==fold]\n        train_ds = make_dataset(train_f['filepath'].tolist(), train_f['label_enc'].values, batch_size=BATCH_SIZE, is_training=True)\n        val_ds = make_dataset(val_f['filepath'].tolist(), val_f['label_enc'].values, batch_size=BATCH_SIZE, is_training=False)\n\n        model = build_model(len(le.classes_), input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), train_base=False)\n        ckpt_path = MODEL_DIR / f'best_fold_{fold}.h5'\n        cb = [\n            callbacks.ModelCheckpoint(str(ckpt_path), monitor='val_loss', save_best_only=True, verbose=1),\n            callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1),\n            callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n        ]\n        history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cb)\n        fold_hist[fold] = history.history\n        # load best\n        model.load_weights(str(ckpt_path))\n        models_for_inference.append(model)\n        # evaluate on val\n        val_preds = model.predict(val_ds)\n        val_pred_labels = val_preds.argmax(axis=1)\n        f1 = f1_score(val_f['label_enc'].values, val_pred_labels, average='micro')\n        print(f'Fold {fold} micro F1: {f1:.4f}')\n        all_val_scores.append(f1)\n\n    print('\\nAll folds micro F1:', all_val_scores)\n    print('Mean:', np.mean(all_val_scores))\nelse:\n    print('Training skipped. Set RUN_TRAIN=True to train models.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:17:17.085675Z","iopub.execute_input":"2025-09-26T12:17:17.086568Z","iopub.status.idle":"2025-09-26T12:36:05.802879Z","shell.execute_reply.started":"2025-09-26T12:17:17.086538Z","shell.execute_reply":"2025-09-26T12:36:05.802238Z"}},"outputs":[{"name":"stdout","text":"\n=== Fold 0 ===\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1758889059.294289     103 service.cc:148] XLA service 0x7912e0003390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1758889059.295779     103 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1758889059.295799     103 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1758889061.286609     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/160\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.0122 - loss: 3.4025      ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1758889072.172893     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1074 - loss: 2.9408\nEpoch 1: val_loss improved from inf to 1.98765, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 127ms/step - accuracy: 0.1080 - loss: 2.9388 - val_accuracy: 0.5664 - val_loss: 1.9877 - learning_rate: 1.0000e-04\nEpoch 2/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4460 - loss: 1.9339\nEpoch 2: val_loss improved from 1.98765 to 1.46847, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4463 - loss: 1.9331 - val_accuracy: 0.7039 - val_loss: 1.4685 - learning_rate: 1.0000e-04\nEpoch 3/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5991 - loss: 1.4784\nEpoch 3: val_loss improved from 1.46847 to 1.17962, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.5992 - loss: 1.4777 - val_accuracy: 0.7734 - val_loss: 1.1796 - learning_rate: 1.0000e-04\nEpoch 4/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6615 - loss: 1.2326\nEpoch 4: val_loss improved from 1.17962 to 0.99932, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.6616 - loss: 1.2322 - val_accuracy: 0.8039 - val_loss: 0.9993 - learning_rate: 1.0000e-04\nEpoch 5/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7161 - loss: 1.0526\nEpoch 5: val_loss improved from 0.99932 to 0.87483, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.7161 - loss: 1.0525 - val_accuracy: 0.8188 - val_loss: 0.8748 - learning_rate: 1.0000e-04\nEpoch 6/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7660 - loss: 0.9172\nEpoch 6: val_loss improved from 0.87483 to 0.78344, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.7659 - loss: 0.9172 - val_accuracy: 0.8453 - val_loss: 0.7834 - learning_rate: 1.0000e-04\nEpoch 7/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7784 - loss: 0.8427\nEpoch 7: val_loss improved from 0.78344 to 0.71348, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7784 - loss: 0.8426 - val_accuracy: 0.8539 - val_loss: 0.7135 - learning_rate: 1.0000e-04\nEpoch 8/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8035 - loss: 0.7457\nEpoch 8: val_loss improved from 0.71348 to 0.65985, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8034 - loss: 0.7458 - val_accuracy: 0.8539 - val_loss: 0.6599 - learning_rate: 1.0000e-04\nEpoch 9/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8054 - loss: 0.7212\nEpoch 9: val_loss improved from 0.65985 to 0.61497, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8055 - loss: 0.7210 - val_accuracy: 0.8562 - val_loss: 0.6150 - learning_rate: 1.0000e-04\nEpoch 10/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8256 - loss: 0.6468\nEpoch 10: val_loss improved from 0.61497 to 0.57709, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8256 - loss: 0.6468 - val_accuracy: 0.8680 - val_loss: 0.5771 - learning_rate: 1.0000e-04\nEpoch 11/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8370 - loss: 0.6105\nEpoch 11: val_loss improved from 0.57709 to 0.54535, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8370 - loss: 0.6106 - val_accuracy: 0.8695 - val_loss: 0.5453 - learning_rate: 1.0000e-04\nEpoch 12/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8323 - loss: 0.6083\nEpoch 12: val_loss improved from 0.54535 to 0.51909, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8323 - loss: 0.6082 - val_accuracy: 0.8781 - val_loss: 0.5191 - learning_rate: 1.0000e-04\nEpoch 13/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8493 - loss: 0.5621\nEpoch 13: val_loss improved from 0.51909 to 0.49465, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8493 - loss: 0.5622 - val_accuracy: 0.8781 - val_loss: 0.4947 - learning_rate: 1.0000e-04\nEpoch 14/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8474 - loss: 0.5413\nEpoch 14: val_loss improved from 0.49465 to 0.47394, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8474 - loss: 0.5413 - val_accuracy: 0.8820 - val_loss: 0.4739 - learning_rate: 1.0000e-04\nEpoch 15/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8640 - loss: 0.5089\nEpoch 15: val_loss improved from 0.47394 to 0.45453, saving model to /kaggle/working/best_fold_0.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.8640 - loss: 0.5090 - val_accuracy: 0.8906 - val_loss: 0.4545 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 15.\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\nFold 0 micro F1: 0.8906\n\n=== Fold 1 ===\nEpoch 1/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1193 - loss: 2.8234\nEpoch 1: val_loss improved from inf to 1.97414, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 108ms/step - accuracy: 0.1198 - loss: 2.8217 - val_accuracy: 0.5094 - val_loss: 1.9741 - learning_rate: 1.0000e-04\nEpoch 2/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4218 - loss: 1.9302\nEpoch 2: val_loss improved from 1.97414 to 1.45819, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4224 - loss: 1.9286 - val_accuracy: 0.7117 - val_loss: 1.4582 - learning_rate: 1.0000e-04\nEpoch 3/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5890 - loss: 1.4858\nEpoch 3: val_loss improved from 1.45819 to 1.17080, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.5892 - loss: 1.4849 - val_accuracy: 0.7906 - val_loss: 1.1708 - learning_rate: 1.0000e-04\nEpoch 4/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6801 - loss: 1.2159\nEpoch 4: val_loss improved from 1.17080 to 0.98989, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.6802 - loss: 1.2157 - val_accuracy: 0.8320 - val_loss: 0.9899 - learning_rate: 1.0000e-04\nEpoch 5/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7100 - loss: 1.0638\nEpoch 5: val_loss improved from 0.98989 to 0.86326, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.7101 - loss: 1.0637 - val_accuracy: 0.8422 - val_loss: 0.8633 - learning_rate: 1.0000e-04\nEpoch 6/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7552 - loss: 0.9340\nEpoch 6: val_loss improved from 0.86326 to 0.77261, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7551 - loss: 0.9339 - val_accuracy: 0.8586 - val_loss: 0.7726 - learning_rate: 1.0000e-04\nEpoch 7/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7717 - loss: 0.8562\nEpoch 7: val_loss improved from 0.77261 to 0.70223, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7717 - loss: 0.8561 - val_accuracy: 0.8641 - val_loss: 0.7022 - learning_rate: 1.0000e-04\nEpoch 8/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7892 - loss: 0.7756\nEpoch 8: val_loss improved from 0.70223 to 0.64698, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7892 - loss: 0.7755 - val_accuracy: 0.8750 - val_loss: 0.6470 - learning_rate: 1.0000e-04\nEpoch 9/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7943 - loss: 0.7273\nEpoch 9: val_loss improved from 0.64698 to 0.60263, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7944 - loss: 0.7271 - val_accuracy: 0.8687 - val_loss: 0.6026 - learning_rate: 1.0000e-04\nEpoch 10/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8195 - loss: 0.6714\nEpoch 10: val_loss improved from 0.60263 to 0.56550, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8195 - loss: 0.6713 - val_accuracy: 0.8781 - val_loss: 0.5655 - learning_rate: 1.0000e-04\nEpoch 11/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8302 - loss: 0.6316\nEpoch 11: val_loss improved from 0.56550 to 0.53385, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8302 - loss: 0.6315 - val_accuracy: 0.8820 - val_loss: 0.5339 - learning_rate: 1.0000e-04\nEpoch 12/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8261 - loss: 0.6145\nEpoch 12: val_loss improved from 0.53385 to 0.50549, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8261 - loss: 0.6143 - val_accuracy: 0.8852 - val_loss: 0.5055 - learning_rate: 1.0000e-04\nEpoch 13/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8364 - loss: 0.5729\nEpoch 13: val_loss improved from 0.50549 to 0.48294, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8364 - loss: 0.5729 - val_accuracy: 0.8867 - val_loss: 0.4829 - learning_rate: 1.0000e-04\nEpoch 14/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8494 - loss: 0.5410\nEpoch 14: val_loss improved from 0.48294 to 0.46013, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8494 - loss: 0.5411 - val_accuracy: 0.8898 - val_loss: 0.4601 - learning_rate: 1.0000e-04\nEpoch 15/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8434 - loss: 0.5324\nEpoch 15: val_loss improved from 0.46013 to 0.44147, saving model to /kaggle/working/best_fold_1.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8434 - loss: 0.5323 - val_accuracy: 0.8961 - val_loss: 0.4415 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 15.\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step\nFold 1 micro F1: 0.8961\n\n=== Fold 2 ===\nEpoch 1/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0765 - loss: 3.0828\nEpoch 1: val_loss improved from inf to 2.10391, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 105ms/step - accuracy: 0.0775 - loss: 3.0785 - val_accuracy: 0.4711 - val_loss: 2.1039 - learning_rate: 1.0000e-04\nEpoch 2/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3960 - loss: 2.0365\nEpoch 2: val_loss improved from 2.10391 to 1.53281, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.3963 - loss: 2.0356 - val_accuracy: 0.6672 - val_loss: 1.5328 - learning_rate: 1.0000e-04\nEpoch 3/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5658 - loss: 1.5439\nEpoch 3: val_loss improved from 1.53281 to 1.22128, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.5662 - loss: 1.5429 - val_accuracy: 0.7547 - val_loss: 1.2213 - learning_rate: 1.0000e-04\nEpoch 4/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6529 - loss: 1.2618\nEpoch 4: val_loss improved from 1.22128 to 1.02706, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.6530 - loss: 1.2612 - val_accuracy: 0.7977 - val_loss: 1.0271 - learning_rate: 1.0000e-04\nEpoch 5/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7045 - loss: 1.0757\nEpoch 5: val_loss improved from 1.02706 to 0.89695, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.7045 - loss: 1.0754 - val_accuracy: 0.8289 - val_loss: 0.8969 - learning_rate: 1.0000e-04\nEpoch 6/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7415 - loss: 0.9534\nEpoch 6: val_loss improved from 0.89695 to 0.79859, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.7415 - loss: 0.9533 - val_accuracy: 0.8508 - val_loss: 0.7986 - learning_rate: 1.0000e-04\nEpoch 7/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7629 - loss: 0.8632\nEpoch 7: val_loss improved from 0.79859 to 0.72432, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7629 - loss: 0.8631 - val_accuracy: 0.8656 - val_loss: 0.7243 - learning_rate: 1.0000e-04\nEpoch 8/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7928 - loss: 0.7804\nEpoch 8: val_loss improved from 0.72432 to 0.66641, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.7928 - loss: 0.7804 - val_accuracy: 0.8656 - val_loss: 0.6664 - learning_rate: 1.0000e-04\nEpoch 9/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8093 - loss: 0.7180\nEpoch 9: val_loss improved from 0.66641 to 0.61788, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8092 - loss: 0.7180 - val_accuracy: 0.8781 - val_loss: 0.6179 - learning_rate: 1.0000e-04\nEpoch 10/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8281 - loss: 0.6631\nEpoch 10: val_loss improved from 0.61788 to 0.57880, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8281 - loss: 0.6632 - val_accuracy: 0.8758 - val_loss: 0.5788 - learning_rate: 1.0000e-04\nEpoch 11/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8211 - loss: 0.6378\nEpoch 11: val_loss improved from 0.57880 to 0.54426, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8211 - loss: 0.6377 - val_accuracy: 0.8836 - val_loss: 0.5443 - learning_rate: 1.0000e-04\nEpoch 12/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8392 - loss: 0.6004\nEpoch 12: val_loss improved from 0.54426 to 0.51573, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8392 - loss: 0.6003 - val_accuracy: 0.8930 - val_loss: 0.5157 - learning_rate: 1.0000e-04\nEpoch 13/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8428 - loss: 0.5778\nEpoch 13: val_loss improved from 0.51573 to 0.49060, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8428 - loss: 0.5777 - val_accuracy: 0.8914 - val_loss: 0.4906 - learning_rate: 1.0000e-04\nEpoch 14/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8543 - loss: 0.5373\nEpoch 14: val_loss improved from 0.49060 to 0.46883, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8543 - loss: 0.5374 - val_accuracy: 0.8914 - val_loss: 0.4688 - learning_rate: 1.0000e-04\nEpoch 15/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8482 - loss: 0.5306\nEpoch 15: val_loss improved from 0.46883 to 0.44849, saving model to /kaggle/working/best_fold_2.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8483 - loss: 0.5305 - val_accuracy: 0.8961 - val_loss: 0.4485 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 15.\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\nFold 2 micro F1: 0.8961\n\n=== Fold 3 ===\nEpoch 1/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1540 - loss: 2.7384\nEpoch 1: val_loss improved from inf to 1.90900, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 101ms/step - accuracy: 0.1551 - loss: 2.7351 - val_accuracy: 0.5727 - val_loss: 1.9090 - learning_rate: 1.0000e-04\nEpoch 2/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4576 - loss: 1.8770\nEpoch 2: val_loss improved from 1.90900 to 1.42187, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.4578 - loss: 1.8762 - val_accuracy: 0.7281 - val_loss: 1.4219 - learning_rate: 1.0000e-04\nEpoch 3/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5899 - loss: 1.4440\nEpoch 3: val_loss improved from 1.42187 to 1.15255, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.5900 - loss: 1.4436 - val_accuracy: 0.7633 - val_loss: 1.1526 - learning_rate: 1.0000e-04\nEpoch 4/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6791 - loss: 1.1877\nEpoch 4: val_loss improved from 1.15255 to 0.98044, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.6791 - loss: 1.1874 - val_accuracy: 0.8125 - val_loss: 0.9804 - learning_rate: 1.0000e-04\nEpoch 5/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7111 - loss: 1.0522\nEpoch 5: val_loss improved from 0.98044 to 0.86064, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7113 - loss: 1.0517 - val_accuracy: 0.8344 - val_loss: 0.8606 - learning_rate: 1.0000e-04\nEpoch 6/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7430 - loss: 0.9243\nEpoch 6: val_loss improved from 0.86064 to 0.77213, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7430 - loss: 0.9241 - val_accuracy: 0.8445 - val_loss: 0.7721 - learning_rate: 1.0000e-04\nEpoch 7/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7707 - loss: 0.8396\nEpoch 7: val_loss improved from 0.77213 to 0.70480, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7707 - loss: 0.8395 - val_accuracy: 0.8602 - val_loss: 0.7048 - learning_rate: 1.0000e-04\nEpoch 8/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7744 - loss: 0.7866\nEpoch 8: val_loss improved from 0.70480 to 0.64995, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7745 - loss: 0.7865 - val_accuracy: 0.8625 - val_loss: 0.6499 - learning_rate: 1.0000e-04\nEpoch 9/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8071 - loss: 0.7129\nEpoch 9: val_loss improved from 0.64995 to 0.60534, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8071 - loss: 0.7129 - val_accuracy: 0.8727 - val_loss: 0.6053 - learning_rate: 1.0000e-04\nEpoch 10/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8174 - loss: 0.6708\nEpoch 10: val_loss improved from 0.60534 to 0.56699, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8174 - loss: 0.6707 - val_accuracy: 0.8797 - val_loss: 0.5670 - learning_rate: 1.0000e-04\nEpoch 11/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8224 - loss: 0.6281\nEpoch 11: val_loss improved from 0.56699 to 0.53533, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8224 - loss: 0.6281 - val_accuracy: 0.8805 - val_loss: 0.5353 - learning_rate: 1.0000e-04\nEpoch 12/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8362 - loss: 0.5888\nEpoch 12: val_loss improved from 0.53533 to 0.50736, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8362 - loss: 0.5889 - val_accuracy: 0.8836 - val_loss: 0.5074 - learning_rate: 1.0000e-04\nEpoch 13/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8306 - loss: 0.5810\nEpoch 13: val_loss improved from 0.50736 to 0.48349, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8307 - loss: 0.5810 - val_accuracy: 0.8883 - val_loss: 0.4835 - learning_rate: 1.0000e-04\nEpoch 14/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8488 - loss: 0.5318\nEpoch 14: val_loss improved from 0.48349 to 0.46221, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8488 - loss: 0.5318 - val_accuracy: 0.8977 - val_loss: 0.4622 - learning_rate: 1.0000e-04\nEpoch 15/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8527 - loss: 0.5306\nEpoch 15: val_loss improved from 0.46221 to 0.44268, saving model to /kaggle/working/best_fold_3.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8527 - loss: 0.5306 - val_accuracy: 0.9055 - val_loss: 0.4427 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 15.\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step\nFold 3 micro F1: 0.9055\n\n=== Fold 4 ===\nEpoch 1/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1285 - loss: 2.8617\nEpoch 1: val_loss improved from inf to 1.99866, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 99ms/step - accuracy: 0.1290 - loss: 2.8600 - val_accuracy: 0.4758 - val_loss: 1.9987 - learning_rate: 1.0000e-04\nEpoch 2/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4133 - loss: 1.9595\nEpoch 2: val_loss improved from 1.99866 to 1.47943, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.4139 - loss: 1.9578 - val_accuracy: 0.6703 - val_loss: 1.4794 - learning_rate: 1.0000e-04\nEpoch 3/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5632 - loss: 1.5154\nEpoch 3: val_loss improved from 1.47943 to 1.18943, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.5635 - loss: 1.5144 - val_accuracy: 0.7586 - val_loss: 1.1894 - learning_rate: 1.0000e-04\nEpoch 4/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6586 - loss: 1.2332\nEpoch 4: val_loss improved from 1.18943 to 1.00410, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.6587 - loss: 1.2329 - val_accuracy: 0.8047 - val_loss: 1.0041 - learning_rate: 1.0000e-04\nEpoch 5/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7144 - loss: 1.0587\nEpoch 5: val_loss improved from 1.00410 to 0.87474, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.7144 - loss: 1.0586 - val_accuracy: 0.8438 - val_loss: 0.8747 - learning_rate: 1.0000e-04\nEpoch 6/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7415 - loss: 0.9397\nEpoch 6: val_loss improved from 0.87474 to 0.78185, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.7417 - loss: 0.9395 - val_accuracy: 0.8555 - val_loss: 0.7819 - learning_rate: 1.0000e-04\nEpoch 7/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7698 - loss: 0.8517\nEpoch 7: val_loss improved from 0.78185 to 0.71046, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.7699 - loss: 0.8515 - val_accuracy: 0.8695 - val_loss: 0.7105 - learning_rate: 1.0000e-04\nEpoch 8/15\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7995 - loss: 0.7637\nEpoch 8: val_loss improved from 0.71046 to 0.65320, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.7995 - loss: 0.7637 - val_accuracy: 0.8773 - val_loss: 0.6532 - learning_rate: 1.0000e-04\nEpoch 9/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8113 - loss: 0.7100\nEpoch 9: val_loss improved from 0.65320 to 0.60690, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8113 - loss: 0.7100 - val_accuracy: 0.8758 - val_loss: 0.6069 - learning_rate: 1.0000e-04\nEpoch 10/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8112 - loss: 0.6815\nEpoch 10: val_loss improved from 0.60690 to 0.56739, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8113 - loss: 0.6814 - val_accuracy: 0.8820 - val_loss: 0.5674 - learning_rate: 1.0000e-04\nEpoch 11/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8236 - loss: 0.6289\nEpoch 11: val_loss improved from 0.56739 to 0.53408, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8237 - loss: 0.6289 - val_accuracy: 0.8914 - val_loss: 0.5341 - learning_rate: 1.0000e-04\nEpoch 12/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8369 - loss: 0.6004\nEpoch 12: val_loss improved from 0.53408 to 0.50525, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8369 - loss: 0.6003 - val_accuracy: 0.8914 - val_loss: 0.5053 - learning_rate: 1.0000e-04\nEpoch 13/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8387 - loss: 0.5643\nEpoch 13: val_loss improved from 0.50525 to 0.48185, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8387 - loss: 0.5643 - val_accuracy: 0.8938 - val_loss: 0.4819 - learning_rate: 1.0000e-04\nEpoch 14/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8442 - loss: 0.5530\nEpoch 14: val_loss improved from 0.48185 to 0.46167, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8443 - loss: 0.5529 - val_accuracy: 0.8938 - val_loss: 0.4617 - learning_rate: 1.0000e-04\nEpoch 15/15\n\u001b[1m159/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8600 - loss: 0.5176\nEpoch 15: val_loss improved from 0.46167 to 0.44209, saving model to /kaggle/working/best_fold_4.h5\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8600 - loss: 0.5176 - val_accuracy: 0.9016 - val_loss: 0.4421 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 15.\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step\nFold 4 micro F1: 0.9016\n\nAll folds micro F1: [0.890625, 0.89609375, 0.89609375, 0.90546875, 0.9015625]\nMean: 0.8979687499999999\n","output_type":"stream"}],"execution_count":8},{"id":"ebdc763a","cell_type":"markdown","source":"## Inference on test set and submission","metadata":{}},{"id":"f6cf56f3","cell_type":"code","source":"if TEST_DIR.exists():\n    # include jpg and png\n    test_files = sorted([p for p in TEST_DIR.rglob(\"*\") if p.suffix.lower() in [\".jpg\", \".png\"]])\n    test_ids = [p.name for p in test_files]\n    test_paths = [str(p) for p in test_files]\nelse:\n    # try to load sample_submission and use IDs\n    if SAMPLE_SUB.exists():\n        sample = pd.read_csv(str(SAMPLE_SUB))\n        test_ids = sample['ID'].astype(str).tolist()\n        test_paths = []\n        for tid in test_ids:\n            p = None\n            for q in TEST_DIR.rglob(tid):   # works for jpg/png\n                p = q\n                break\n            if p is None:\n                p = TEST_DIR / tid\n            test_paths.append(str(p))\n    else:\n        test_ids = [f'{i:04d}.jpg' for i in range(1,1601)]\n        test_paths = [str(TEST_DIR/tid) for tid in test_ids]\n\nprint('Test samples:', len(test_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:01:33.193381Z","iopub.execute_input":"2025-09-26T13:01:33.194023Z","iopub.status.idle":"2025-09-26T13:01:35.104926Z","shell.execute_reply.started":"2025-09-26T13:01:33.193998Z","shell.execute_reply":"2025-09-26T13:01:35.104248Z"}},"outputs":[{"name":"stdout","text":"Test samples: 1600\n","output_type":"stream"}],"execution_count":37},{"id":"1da7d1fb-0091-4703-ab3a-d499d3b1e38b","cell_type":"code","source":"# Make test dataset\ntest_ds = make_dataset(test_paths, labels=None, batch_size=BATCH_SIZE, is_training=False)\n\n# Prepare inference models: if none trained, attempt to load first checkpoint\nif len(models_for_inference)==0:\n    ckpt0 = MODEL_DIR / 'best_fold_0.h5'\n    if ckpt0.exists():\n        print('Loading', ckpt0)\n        m = build_model(len(le.classes_), input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), train_base=False)\n        m.load_weights(str(ckpt0))\n        models_for_inference.append(m)\n\nif len(models_for_inference)==0:\n    print('No model available for inference. Set RUN_TRAIN=True and run training, or upload a checkpoint to /kaggle/working.')\nelse:\n    # average predictions\n    import numpy as np\n    preds = None\n    for m in models_for_inference:\n        p = m.predict(test_ds, verbose=1)\n        if preds is None:\n            preds = p\n        else:\n            preds += p\n    preds = preds / len(models_for_inference)\n    pred_labels_idx = preds.argmax(axis=1)\n    pred_labels = le.inverse_transform(pred_labels_idx)\n\n    submission_df = pd.DataFrame({'ID': test_ids, 'TARGET': pred_labels})\n    out_path = Path('/kaggle/working/submission.csv')\n    submission_df.to_csv(out_path, index=False)\n    print('Saved submission to', out_path)\n    display(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:03:07.445119Z","iopub.execute_input":"2025-09-26T13:03:07.445827Z","iopub.status.idle":"2025-09-26T13:03:55.493405Z","shell.execute_reply.started":"2025-09-26T13:03:07.445801Z","shell.execute_reply":"2025-09-26T13:03:55.492746Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\nSaved submission to /kaggle/working/submission.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         ID      TARGET\n0  0000.jpg   KARACADAG\n1  0001.jpg      BRRI67\n2  0002.jpg  BINADHAN16\n3  0003.jpg  BINADHAN16\n4  0004.jpg   KARACADAG","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000.jpg</td>\n      <td>KARACADAG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001.jpg</td>\n      <td>BRRI67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002.jpg</td>\n      <td>BINADHAN16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003.jpg</td>\n      <td>BINADHAN16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004.jpg</td>\n      <td>KARACADAG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38}]}